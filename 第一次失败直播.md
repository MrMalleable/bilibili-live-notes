第一次直播

本次目标：

学会用golang的爬虫框架colly来爬取虎扑NBA的新闻。



### 爬虫之前

1. 我们要爬什么内容
2. 分析页面的结构
3. 编写代码
4. 调试



1. **首先来看下我们要爬的页面。**

   [篮球新闻 - 虎扑社区 (hupu.com)](https://bbs.hupu.com/4860)

   ![image-20210913215857229](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913215857229.png)

   我们需要对上面这个列表的每条新闻去浏览，然后获取每条新闻的具体内容，最后我们程序打印的就是新闻的标题加上新闻的内容。这就是我们的最终目标。

2. **分析要爬取的内容的页面结构**

F12打开浏览器控制台

![image-20210913220113394](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913220113394.png)

我们可以看到左边一条新闻的标题就对应右边页面源码的一个<li>标签，这里需要我们对前端的html知识有了解,在这个列表中，我们可以再分析下点击这个新闻标题具体的链接是什么。

![image-20210913220405005](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913220405005.png)

从上图中我们可以看到这条新闻的标题对应的跳转链接是一个a标签，跳转地址是[[流言板\]新赛季MVP赔率：东契奇榜首，阿德托昆博第二 - 虎扑社区 (hupu.com)](https://bbs.hupu.com/45194922.html)，其实就是https://bbs.hupu.com拼上a标签的href对应的字符串，就是我们这条新闻具体的链接。我们拿到这个链接之后就得去访问这个链接对吧，然后从这个链接的页面内容获取到新闻的标题和内容。

老样子，还是要分析页面的结构，找到标题和内容对应的标签位置。首先来看看标题要怎么找，检查元素发现如下图所示就能找到这条新闻的标题。

![image-20210913221034751](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913221034751.png)

同理，我们来找一下新闻的内容。

![image-20210913221212902](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913221212902.png)

所以整体的思路就是先把新闻列表的每一条新闻的跳转链接先获取到，然后对每个新闻跳转链接再去查找对应页面的标题和内容。

整体逻辑是不是很简单？那就让我们开始写代码吧。

3. **编写代码**

   - 新建go modules工程，推荐go modules新建工程的方式，再配置一下GOPROXY变量，下载依赖就会比较快，具体原理我暂时也不懂哇！![image-20210913221518765](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913221518765.png)
   - 编写main.go文件

   一般会因为本地没有依赖而报红，这是只需要在终端执行go get+对应的依赖名称即可。

   ```sh
   # go modules会使得下载比较快，如果正常从github.com下载的话你会发现会疯掉的
   go get github.com/gocolly/colly
   ```

   ![image-20210913222013114](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913222013114.png)

执行完上述命令就代表这个依赖已经下载并在本地可以使用了。

对了，这里要讲一下在编写爬虫的时候如何去定位页面的元素，常用的就是通过选择器或者Xpath来定位，这里需要自己去百度了解下，我就不赘述了，我这边采用的是选择器定位。

我们在新闻列表，可以观察到每个新闻标题的a标签的class属性都是p-title,所以抓住这一点就可以定位到这个新闻标题了。



第一版的代码：

```go
package main

import (
	"fmt"
	"github.com/gocolly/colly"
)

func main() {
	// 新建一个爬虫收集器
	c := colly.NewCollector(
		// 这里可以指定一些爬虫的基本配置,一般这种配置都是为了模拟浏览器，不让网站发现你是爬虫
		colly.AllowedDomains("bbs.hupu.com"),
		// 这里从浏览器拷贝一个过来吧
		colly.UserAgent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.44"),
	)

	// Colly框架比较方便的原因我感觉就是你可以在回调函数里面写好逻辑，然后去请求页面即可
	// 我们首先要去请求nba新闻列表，拿到每个新闻的跳转链接
	c.OnHTML(".p-title", func(e *colly.HTMLElement) {
		link := e.Attr("href")
		fmt.Printf("新闻列表的跳转链接: %q -> %s\n", e.Text, link)
		// 继续访问这个跳转链接
		c.Visit(e.Request.AbsoluteURL(link))
	})

	//这个回调函数和上面的回调函数不一样，这里主要处理具体的新闻详情页，也就是我们要在这个页面拿到标题和内容
	c.OnHTML(".bbs-post-content", func(e *colly.HTMLElement) {
		// 1. 找到标题
		titleDom := e.DOM.Find("post-user-comp-info-bottom-title")
		fmt.Println("标题为："+titleDom.Text())
		// 2. 找到内容
		contentDom := e.DOM.Find("thread-content-detail")
		fmt.Println("内容为："+contentDom.Text())
	})


	// 爬虫的起始页面
	c.Visit("https://bbs.hupu.com/4860")
}
```

我们来试一把，我觉得大概率是漏洞百出的。

完美，直接没有输出。

![image-20210913223736032](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210913223736032.png)

4. **调试代码**

写代码容易，调试代码难啊，报错都没有，这是最蛋疼的。

我感觉是页面还没加载完成导致的，得想一想如何解决这个问题。



有点难受，QAQ



果然是动态加载的数据，哭了，要放弃了。早点睡吧今天~

我以为会很简单的，没想到现在的我还是这么菜，耻辱下播了！



洗完澡复盘了一下，找到了问题所在。

- 第一个问题就是新闻列表的class属性由p-title换成了truetit，不知道为什么控制台打印的源代码里面class=trueit而页面渲染之后的class=p-title.
- 第二个问题就是在具体的新闻详情页面，我发现选择器前忘记加小数点了，因为class选择器的话都是需要在class属性前加上.

修改之后的代码是这样的：

```go
package main

import (
	"fmt"
	"github.com/gocolly/colly"
)

func main() {
	// 新建一个爬虫收集器
	c := colly.NewCollector(
		// 这里可以指定一些爬虫的基本配置,一般这种配置都是为了模拟浏览器，不让网站发现你是爬虫
		colly.AllowedDomains("bbs.hupu.com"),
		// 这里从浏览器拷贝一个过来吧
		colly.UserAgent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36 Edg/93.0.961.44"),
	)

	// Colly框架比较方便的原因我感觉就是你可以在回调函数里面写好逻辑，然后去请求页面即可
	// 我们首先要去请求nba新闻列表，拿到每个新闻的跳转链接
	c.OnHTML(".truetit", func(e *colly.HTMLElement) {
		link := e.Attr("href")
		//fmt.Printf("新闻列表的跳转链接: %q -> %s\n", e.Text, "https://bbs.hupu.com/"+link)
		// 继续访问这个跳转链接
		c.Visit(e.Request.AbsoluteURL(link))
	})

	//这个回调函数和上面的回调函数不一样，这里主要处理具体的新闻详情页，也就是我们要在这个页面拿到标题和内容
	c.OnHTML(".bbs-post-content", func(e *colly.HTMLElement) {
		// 1. 找到标题
		titleDom := e.DOM.Find(".post-user-comp-info-bottom-title")
		fmt.Println("标题为："+titleDom.Text())
		// 2. 找到内容
		contentDom := e.DOM.Find(".thread-content-detail")
		fmt.Println("内容为："+contentDom.Text())

		fmt.Printf("\n\n")
	})

	c.OnRequest(func(request *colly.Request) {
		//fmt.Println("访问 >> ", request.URL)
	})

	c.OnResponse(func(response *colly.Response) {
		if response.Request.URL.Path != "/4860"{
			//fmt.Println(string(response.Body))
		}
	})


	// 爬虫的起始页面
	c.Visit("https://bbs.hupu.com/4860")
	c.Wait()
}
```



最后实现的效果图就是下面这样的：

![image-20210914000840617](C:\Users\ilovewl\AppData\Roaming\Typora\typora-user-images\image-20210914000840617.png)



通过上面可以看到很丑，但是至少功能是实现了的（手动捂脸）。



其实，仔细一想，我们发现上面的新闻列表只爬了第一页的新闻，对吧，如果需要不停地爬下一页的话，就得再去访问下一页的地址。

有兴趣可以研究下怎么拿到下一页的地址。



睡觉了，搁笔至此，溜了，别忘了一键三连啊！